{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"widgets":{"application/vnd.jupyter.widget-state+json":{"c4d1d4203a8f46b0b3298f68627a2c64":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0e48ba5970f74f01806aa9a025fb668a","IPY_MODEL_671142ff85fa4647a167703e5fa41ef1","IPY_MODEL_d84690912d934528bebeae11581799c5"],"layout":"IPY_MODEL_e988aed855ca40f797105affde1f8b79"}},"0e48ba5970f74f01806aa9a025fb668a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eed7404224174802983a5b4631c8b000","placeholder":"​","style":"IPY_MODEL_0558f714183f465683cec2971933ab97","value":"Map: 100%"}},"671142ff85fa4647a167703e5fa41ef1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ebbc7a2145504296b442e39b0486af82","max":99999,"min":0,"orientation":"horizontal","style":"IPY_MODEL_aef76d301bd44687bf4d21506f5e3d11","value":99999}},"d84690912d934528bebeae11581799c5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_78aee314a45448b7b03bf7d8cf893344","placeholder":"​","style":"IPY_MODEL_bfa696e15a7c415cb2f04f161ffebc59","value":" 99999/99999 [00:32&lt;00:00, 2252.42 examples/s]"}},"e988aed855ca40f797105affde1f8b79":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eed7404224174802983a5b4631c8b000":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0558f714183f465683cec2971933ab97":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ebbc7a2145504296b442e39b0486af82":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aef76d301bd44687bf4d21506f5e3d11":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"78aee314a45448b7b03bf7d8cf893344":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bfa696e15a7c415cb2f04f161ffebc59":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"00aaf32501a749dc824721e8644ac575":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_390c97b831ee48a9926a31faec6112ab","IPY_MODEL_4023dd8ab62346c78f29ccb4aa26f812","IPY_MODEL_0a4e88070eea48ca81e147cd42e84ca6"],"layout":"IPY_MODEL_de377f7b0b714056bd087607b171a631"}},"390c97b831ee48a9926a31faec6112ab":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_41b6dc9c8db64687b5c6ff59b3770306","placeholder":"​","style":"IPY_MODEL_dc73d5139ab545bea16b4ad664323cc5","value":"Map: 100%"}},"4023dd8ab62346c78f29ccb4aa26f812":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b86ee503342f431da7019c357e1dfc46","max":9999,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5db907cf35e64b51b07f906e31ef5e69","value":9999}},"0a4e88070eea48ca81e147cd42e84ca6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fc8bcb34a11941639673c328f4c5e086","placeholder":"​","style":"IPY_MODEL_0c56e115172c4b1a926c0fa806db13ff","value":" 9999/9999 [00:02&lt;00:00, 3764.02 examples/s]"}},"de377f7b0b714056bd087607b171a631":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"41b6dc9c8db64687b5c6ff59b3770306":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc73d5139ab545bea16b4ad664323cc5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b86ee503342f431da7019c357e1dfc46":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5db907cf35e64b51b07f906e31ef5e69":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fc8bcb34a11941639673c328f4c5e086":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c56e115172c4b1a926c0fa806db13ff":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers datasets","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mnkMSgoh_3AW","outputId":"4846f724-6a99-471d-b724-3c4779321b73","trusted":true,"execution":{"iopub.status.busy":"2024-12-04T21:08:31.300688Z","iopub.execute_input":"2024-12-04T21:08:31.301143Z","iopub.status.idle":"2024-12-04T21:08:39.706599Z","shell.execute_reply.started":"2024-12-04T21:08:31.301097Z","shell.execute_reply":"2024-12-04T21:08:39.705698Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.46.3)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.1.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.26.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (17.0.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.3)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.6.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader\nfrom transformers import BertTokenizer, BertForSequenceClassification, AdamW\nfrom datasets import load_dataset","metadata":{"id":"M_5T4EOi_4aG","trusted":true,"execution":{"iopub.status.busy":"2024-12-04T21:08:39.708494Z","iopub.execute_input":"2024-12-04T21:08:39.708821Z","iopub.status.idle":"2024-12-04T21:08:46.204945Z","shell.execute_reply.started":"2024-12-04T21:08:39.708788Z","shell.execute_reply":"2024-12-04T21:08:46.203977Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"from transformers import DistilBertTokenizer, DistilBertForSequenceClassification","metadata":{"id":"NJWRtbO0oqeB","trusted":true,"execution":{"iopub.status.busy":"2024-12-04T21:08:46.210739Z","iopub.execute_input":"2024-12-04T21:08:46.211085Z","iopub.status.idle":"2024-12-04T21:08:46.221072Z","shell.execute_reply.started":"2024-12-04T21:08:46.211046Z","shell.execute_reply":"2024-12-04T21:08:46.220266Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Load the FEVER dataset\nfever = load_dataset(\"fever\", \"v1.0\")\n\n# Label mappings\nlabel2id = {\"SUPPORTS\": 0, \"REFUTES\": 1, \"NOT ENOUGH INFO\": 2}\nid2label = {v: k for k, v in label2id.items()}","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E7-z9A6m_6zP","outputId":"a9540071-c352-4a61-9940-27858637cc5a","trusted":true,"execution":{"iopub.status.busy":"2024-12-04T21:08:46.222317Z","iopub.execute_input":"2024-12-04T21:08:46.222685Z","iopub.status.idle":"2024-12-04T21:08:49.039617Z","shell.execute_reply.started":"2024-12-04T21:08:46.222639Z","shell.execute_reply":"2024-12-04T21:08:49.038890Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# # Load tokenizer and model\n# tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n# model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3, hidden_dropout_prob=0.2, attention_probs_dropout_prob=0.2)\n\ntokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\nmodel = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=3)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QKhi69iv_9tp","outputId":"0b6733e5-b975-4991-c8ac-caedc0b92a71","trusted":true,"execution":{"iopub.status.busy":"2024-12-04T21:08:49.040719Z","iopub.execute_input":"2024-12-04T21:08:49.040990Z","iopub.status.idle":"2024-12-04T21:08:49.724737Z","shell.execute_reply.started":"2024-12-04T21:08:49.040963Z","shell.execute_reply":"2024-12-04T21:08:49.723749Z"}},"outputs":[{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Preprocess data\ndef preprocess_data(batch):\n    inputs = tokenizer(batch[\"claim\"], padding=\"max_length\", truncation=True, max_length=128)\n    inputs[\"labels\"] = [label2id[label] for label in batch[\"label\"]]\n    return inputs","metadata":{"id":"F14Hs48CMd3g","trusted":true,"execution":{"iopub.status.busy":"2024-12-04T21:08:49.726110Z","iopub.execute_input":"2024-12-04T21:08:49.726743Z","iopub.status.idle":"2024-12-04T21:08:49.731393Z","shell.execute_reply.started":"2024-12-04T21:08:49.726701Z","shell.execute_reply":"2024-12-04T21:08:49.730467Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"print(len(fever['train']))\nprint(len(fever['labelled_dev']))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T21:09:28.645851Z","iopub.execute_input":"2024-12-04T21:09:28.646178Z","iopub.status.idle":"2024-12-04T21:09:28.651145Z","shell.execute_reply.started":"2024-12-04T21:09:28.646150Z","shell.execute_reply":"2024-12-04T21:09:28.650127Z"}},"outputs":[{"name":"stdout","text":"311431\n37566\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"from datasets import Dataset\n\n# Preprocess the data\ntrain_data = fever[\"train\"].map(preprocess_data, batched=True)\nval_data = fever[\"labelled_dev\"].map(preprocess_data, batched=True)\n\n# Convert to PyTorch format\ntrain_data.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\nval_data.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n\n# Create DataLoaders\ntrain_dataloader = DataLoader(train_data, batch_size=32, shuffle=True)\nval_dataloader = DataLoader(val_data, batch_size=32)\n\nprint(f\"Training examples: {len(train_data)}, Validation examples: {len(val_data)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T21:10:19.912941Z","iopub.execute_input":"2024-12-04T21:10:19.913318Z","iopub.status.idle":"2024-12-04T21:10:20.508463Z","shell.execute_reply.started":"2024-12-04T21:10:19.913287Z","shell.execute_reply":"2024-12-04T21:10:20.507430Z"},"colab":{"base_uri":"https://localhost:8080/","height":99,"referenced_widgets":["c4d1d4203a8f46b0b3298f68627a2c64","0e48ba5970f74f01806aa9a025fb668a","671142ff85fa4647a167703e5fa41ef1","d84690912d934528bebeae11581799c5","e988aed855ca40f797105affde1f8b79","eed7404224174802983a5b4631c8b000","0558f714183f465683cec2971933ab97","ebbc7a2145504296b442e39b0486af82","aef76d301bd44687bf4d21506f5e3d11","78aee314a45448b7b03bf7d8cf893344","bfa696e15a7c415cb2f04f161ffebc59","00aaf32501a749dc824721e8644ac575","390c97b831ee48a9926a31faec6112ab","4023dd8ab62346c78f29ccb4aa26f812","0a4e88070eea48ca81e147cd42e84ca6","de377f7b0b714056bd087607b171a631","41b6dc9c8db64687b5c6ff59b3770306","dc73d5139ab545bea16b4ad664323cc5","b86ee503342f431da7019c357e1dfc46","5db907cf35e64b51b07f906e31ef5e69","fc8bcb34a11941639673c328f4c5e086","0c56e115172c4b1a926c0fa806db13ff"]},"id":"_gIGpYFtL5TD","outputId":"717e3b24-491f-4092-bfa4-27ebe5fe288e"},"outputs":[{"name":"stdout","text":"Training examples: 311431, Validation examples: 37566\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# train_dataloader = DataLoader(train_data, batch_size=128, shuffle=True)\n# val_dataloader = DataLoader(val_data, batch_size=128)\n\n# Optimizer\noptimizer = AdamW(model.parameters(), lr=1e-5)\n\n# Training loop\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-2Q9cha3ACVm","outputId":"4c56d359-e0c7-482b-95d0-0f10c46c53df","trusted":true,"execution":{"iopub.status.busy":"2024-12-04T21:10:24.638399Z","iopub.execute_input":"2024-12-04T21:10:24.639204Z","iopub.status.idle":"2024-12-04T21:10:24.913229Z","shell.execute_reply.started":"2024-12-04T21:10:24.639167Z","shell.execute_reply":"2024-12-04T21:10:24.912406Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"DistilBertForSequenceClassification(\n  (distilbert): DistilBertModel(\n    (embeddings): Embeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (transformer): Transformer(\n      (layer): ModuleList(\n        (0-5): 6 x TransformerBlock(\n          (attention): DistilBertSdpaAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n            (activation): GELUActivation()\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n      )\n    )\n  )\n  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n  (classifier): Linear(in_features=768, out_features=3, bias=True)\n  (dropout): Dropout(p=0.2, inplace=False)\n)"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"from tqdm import tqdm\n\nfor epoch in range(5):  # Number of epochs\n    model.train()\n    total_loss = 0\n    correct_predictions = 0\n    total_predictions = 0\n\n    # Wrap the DataLoader with TQDM for a progress bar\n    train_progress = tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}\")\n\n    for batch in train_progress:\n        inputs = {key: val.to(device) for key, val in batch.items() if key != \"labels\"}\n        labels = batch[\"labels\"].to(device)\n\n        # Forward pass\n        outputs = model(**inputs, labels=labels)\n        loss = outputs.loss\n        logits = outputs.logits\n\n        # Backward pass\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n\n        # Calculate predictions and update accuracy metrics\n        predictions = torch.argmax(logits, dim=1)\n        correct_predictions += (predictions == labels).sum().item()\n        total_predictions += labels.size(0)\n\n        # Update TQDM with the current batch loss and accuracy\n        train_progress.set_postfix(loss=loss.item(), accuracy=correct_predictions / total_predictions)\n\n    # Calculate epoch-level accuracy\n    epoch_accuracy = correct_predictions / total_predictions\n\n    # Print epoch-level loss and accuracy\n    print(f\"Epoch {epoch + 1}, Loss: {total_loss / len(train_dataloader):.4f}, Accuracy: {epoch_accuracy:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T21:10:25.277946Z","iopub.execute_input":"2024-12-04T21:10:25.278854Z","iopub.status.idle":"2024-12-04T23:38:50.349574Z","shell.execute_reply.started":"2024-12-04T21:10:25.278816Z","shell.execute_reply":"2024-12-04T23:38:50.348498Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"Z3b3TIIwL5TF","outputId":"625d1188-852d-4f4b-a6e6-06b0ac99fbd7"},"outputs":[{"name":"stderr","text":"Epoch 1: 100%|██████████| 9733/9733 [29:38<00:00,  5.47it/s, accuracy=0.806, loss=0.879]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Loss: 0.4976, Accuracy: 0.8060\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2: 100%|██████████| 9733/9733 [29:39<00:00,  5.47it/s, accuracy=0.864, loss=1.31]  \n","output_type":"stream"},{"name":"stdout","text":"Epoch 2, Loss: 0.3666, Accuracy: 0.8641\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3:  74%|███████▍  | 7224/9733 [22:01<07:36,  5.50it/s, accuracy=0.895, loss=0.335] IOPub message rate exceeded.\nThe notebook server will temporarily stop sending output\nto the client in order to avoid crashing it.\nTo change this limit, set the config variable\n`--NotebookApp.iopub_msg_rate_limit`.\n\nCurrent values:\nNotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\nNotebookApp.rate_limit_window=3.0 (secs)\n\nEpoch 3: 100%|██████████| 9733/9733 [29:39<00:00,  5.47it/s, accuracy=0.895, loss=0.0608]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3, Loss: 0.2927, Accuracy: 0.8952\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4: 100%|██████████| 9733/9733 [29:42<00:00,  5.46it/s, accuracy=0.916, loss=0.14]  \n","output_type":"stream"},{"name":"stdout","text":"Epoch 4, Loss: 0.2375, Accuracy: 0.9158\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5: 100%|██████████| 9733/9733 [29:44<00:00,  5.46it/s, accuracy=0.931, loss=0.0214] ","output_type":"stream"},{"name":"stdout","text":"Epoch 5, Loss: 0.1961, Accuracy: 0.9307\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, classification_report\n\n\nmodel.eval()\nall_preds = []\nall_labels = []\n\nwith torch.no_grad():\n    for batch in val_dataloader:\n        inputs = {key: val.to(device) for key, val in batch.items() if key != \"labels\"}\n        labels = batch[\"labels\"].to(device)\n\n        outputs = model(**inputs)\n        logits = outputs.logits\n\n        # Get predictions (the index of the highest logit)\n        preds = torch.argmax(logits, dim=1)\n\n        all_preds.extend(preds.cpu().numpy())\n        all_labels.extend(labels.cpu().numpy())\n\naccuracy = accuracy_score(all_labels, all_preds)\nprint(f\"Validation Accuracy: {accuracy:.4f}\")\nprint(\"Classification Report:\")\nprint(classification_report(all_labels, all_preds, target_names=[\"SUPPORTS\", \"REFUTES\", \"NOT ENOUGH INFO\"]))","metadata":{"id":"SFBpOtTsNJ07","trusted":true,"colab":{"base_uri":"https://localhost:8080/","height":216},"outputId":"cf014ac8-e707-4cf6-8dde-58a96a2f9f59","execution":{"iopub.status.busy":"2024-12-04T23:38:50.351670Z","iopub.execute_input":"2024-12-04T23:38:50.352151Z","iopub.status.idle":"2024-12-04T23:39:54.741691Z","shell.execute_reply.started":"2024-12-04T23:38:50.352101Z","shell.execute_reply":"2024-12-04T23:39:54.740764Z"}},"outputs":[{"name":"stdout","text":"Validation Accuracy: 0.6801\nClassification Report:\n                 precision    recall  f1-score   support\n\n       SUPPORTS       0.66      0.81      0.72     14608\n        REFUTES       0.79      0.69      0.73     14017\nNOT ENOUGH INFO       0.56      0.46      0.50      8941\n\n       accuracy                           0.68     37566\n      macro avg       0.67      0.65      0.65     37566\n   weighted avg       0.68      0.68      0.68     37566\n\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# Function to predict the class of a particular claim\ndef predict_claim_class(claim):\n    # Preprocess the claim (same way as during training)\n    inputs = tokenizer(claim, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\").to(device)\n\n    # Make predictions\n    with torch.no_grad():\n        outputs = model(**inputs)\n        logits = outputs.logits\n\n    # Get the predicted class (index of max logit)\n    predicted_class_id = torch.argmax(logits, dim=1).item()\n\n    # Convert class ID to label\n    predicted_label = id2label[predicted_class_id]\n\n    return predicted_label\n","metadata":{"trusted":true,"id":"-MyHslatL5TF","execution":{"iopub.status.busy":"2024-12-04T23:39:54.742925Z","iopub.execute_input":"2024-12-04T23:39:54.743786Z","iopub.status.idle":"2024-12-04T23:39:54.749124Z","shell.execute_reply.started":"2024-12-04T23:39:54.743744Z","shell.execute_reply":"2024-12-04T23:39:54.748201Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Example usage:\nclaim = \"The Atlantic Ocean is the largest ocean on Earth.\"\npredicted_label = predict_claim_class(claim)\nprint(f\"The claim '{claim}' belongs to the class: {predicted_label}\")","metadata":{"trusted":true,"id":"SNYzz-XiL5TF","execution":{"iopub.status.busy":"2024-12-04T23:39:54.751290Z","iopub.execute_input":"2024-12-04T23:39:54.751780Z","iopub.status.idle":"2024-12-04T23:39:54.772238Z","shell.execute_reply.started":"2024-12-04T23:39:54.751729Z","shell.execute_reply":"2024-12-04T23:39:54.771522Z"}},"outputs":[{"name":"stdout","text":"The claim 'The Atlantic Ocean is the largest ocean on Earth.' belongs to the class: SUPPORTS\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"","metadata":{"trusted":true,"id":"3kntvb2CL5TG"},"outputs":[],"execution_count":null}]}