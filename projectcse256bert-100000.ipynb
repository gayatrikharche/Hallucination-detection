{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"widgets":{"application/vnd.jupyter.widget-state+json":{"c4d1d4203a8f46b0b3298f68627a2c64":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0e48ba5970f74f01806aa9a025fb668a","IPY_MODEL_671142ff85fa4647a167703e5fa41ef1","IPY_MODEL_d84690912d934528bebeae11581799c5"],"layout":"IPY_MODEL_e988aed855ca40f797105affde1f8b79"}},"0e48ba5970f74f01806aa9a025fb668a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eed7404224174802983a5b4631c8b000","placeholder":"​","style":"IPY_MODEL_0558f714183f465683cec2971933ab97","value":"Map: 100%"}},"671142ff85fa4647a167703e5fa41ef1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ebbc7a2145504296b442e39b0486af82","max":99999,"min":0,"orientation":"horizontal","style":"IPY_MODEL_aef76d301bd44687bf4d21506f5e3d11","value":99999}},"d84690912d934528bebeae11581799c5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_78aee314a45448b7b03bf7d8cf893344","placeholder":"​","style":"IPY_MODEL_bfa696e15a7c415cb2f04f161ffebc59","value":" 99999/99999 [00:32&lt;00:00, 2252.42 examples/s]"}},"e988aed855ca40f797105affde1f8b79":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eed7404224174802983a5b4631c8b000":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0558f714183f465683cec2971933ab97":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ebbc7a2145504296b442e39b0486af82":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aef76d301bd44687bf4d21506f5e3d11":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"78aee314a45448b7b03bf7d8cf893344":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bfa696e15a7c415cb2f04f161ffebc59":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"00aaf32501a749dc824721e8644ac575":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_390c97b831ee48a9926a31faec6112ab","IPY_MODEL_4023dd8ab62346c78f29ccb4aa26f812","IPY_MODEL_0a4e88070eea48ca81e147cd42e84ca6"],"layout":"IPY_MODEL_de377f7b0b714056bd087607b171a631"}},"390c97b831ee48a9926a31faec6112ab":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_41b6dc9c8db64687b5c6ff59b3770306","placeholder":"​","style":"IPY_MODEL_dc73d5139ab545bea16b4ad664323cc5","value":"Map: 100%"}},"4023dd8ab62346c78f29ccb4aa26f812":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b86ee503342f431da7019c357e1dfc46","max":9999,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5db907cf35e64b51b07f906e31ef5e69","value":9999}},"0a4e88070eea48ca81e147cd42e84ca6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fc8bcb34a11941639673c328f4c5e086","placeholder":"​","style":"IPY_MODEL_0c56e115172c4b1a926c0fa806db13ff","value":" 9999/9999 [00:02&lt;00:00, 3764.02 examples/s]"}},"de377f7b0b714056bd087607b171a631":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"41b6dc9c8db64687b5c6ff59b3770306":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc73d5139ab545bea16b4ad664323cc5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b86ee503342f431da7019c357e1dfc46":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5db907cf35e64b51b07f906e31ef5e69":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fc8bcb34a11941639673c328f4c5e086":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c56e115172c4b1a926c0fa806db13ff":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers datasets","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mnkMSgoh_3AW","outputId":"4846f724-6a99-471d-b724-3c4779321b73","trusted":true,"execution":{"iopub.status.busy":"2024-12-03T15:32:14.726202Z","iopub.execute_input":"2024-12-03T15:32:14.726540Z","iopub.status.idle":"2024-12-03T15:32:24.030032Z","shell.execute_reply.started":"2024-12-03T15:32:14.726497Z","shell.execute_reply":"2024-12-03T15:32:24.028813Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.45.1)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.0.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader\nfrom transformers import BertTokenizer, BertForSequenceClassification, AdamW\nfrom datasets import load_dataset","metadata":{"id":"M_5T4EOi_4aG","trusted":true,"execution":{"iopub.status.busy":"2024-12-03T15:32:24.031520Z","iopub.execute_input":"2024-12-03T15:32:24.031901Z","iopub.status.idle":"2024-12-03T15:32:29.542379Z","shell.execute_reply.started":"2024-12-03T15:32:24.031863Z","shell.execute_reply":"2024-12-03T15:32:29.541682Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"from transformers import DistilBertTokenizer, DistilBertForSequenceClassification","metadata":{"id":"NJWRtbO0oqeB","trusted":true,"execution":{"iopub.status.busy":"2024-12-03T15:32:29.543417Z","iopub.execute_input":"2024-12-03T15:32:29.543837Z","iopub.status.idle":"2024-12-03T15:32:29.553317Z","shell.execute_reply.started":"2024-12-03T15:32:29.543809Z","shell.execute_reply":"2024-12-03T15:32:29.552459Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Load the FEVER dataset\nfever = load_dataset(\"fever\", \"v1.0\")\n\n# Label mappings\nlabel2id = {\"SUPPORTS\": 0, \"REFUTES\": 1, \"NOT ENOUGH INFO\": 2}\nid2label = {v: k for k, v in label2id.items()}","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E7-z9A6m_6zP","outputId":"a9540071-c352-4a61-9940-27858637cc5a","trusted":true,"execution":{"iopub.status.busy":"2024-12-03T15:32:29.554395Z","iopub.execute_input":"2024-12-03T15:32:29.554763Z","iopub.status.idle":"2024-12-03T15:34:55.717659Z","shell.execute_reply.started":"2024-12-03T15:32:29.554724Z","shell.execute_reply":"2024-12-03T15:34:55.716983Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"fever.py:   0%|          | 0.00/10.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf86c1c605a4498d8d71fd25e24901fb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/11.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"783069cae7104cd2a08f530bd1f64441"}},"metadata":{}},{"output_type":"stream","name":"stdin","text":"The repository for fever contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/fever.\nYou can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n\nDo you wish to run the custom code? [y/N]  y\n"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/33.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a295eca0ea4b4df2a707736ad23af9a1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/4.35M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2565d91011641a4b851d6bffc2e8217"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/1.53M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"626de88ac8d04e1792d3c3b08fa774c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/1.60M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45289e6457d74c37affee407afafd65a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/2.17M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27bbb8e2409d45c6a6858a533eda0413"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/2.18M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e623fd06442c41698da0625a17389f4c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/311431 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7bbe741c1a5e47bba2c37eed3158949c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating labelled_dev split:   0%|          | 0/37566 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"072f64385a1d44f39b9ed6d925db30eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating unlabelled_dev split:   0%|          | 0/19998 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9bc0e5e56f9b4df182a9187353754ffc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating unlabelled_test split:   0%|          | 0/19998 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae34a293fd8a489daf0f671d4bbfd628"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating paper_dev split:   0%|          | 0/18999 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c26ada27a2f14d3ba41e923a89f66798"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating paper_test split:   0%|          | 0/18567 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b5a4a54d3e741809c0f12e32ccaea96"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"# # Load tokenizer and model\n# tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n# model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3, hidden_dropout_prob=0.2, attention_probs_dropout_prob=0.2)\n\ntokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\nmodel = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QKhi69iv_9tp","outputId":"0b6733e5-b975-4991-c8ac-caedc0b92a71","trusted":true,"execution":{"iopub.status.busy":"2024-12-03T15:34:55.720482Z","iopub.execute_input":"2024-12-03T15:34:55.720780Z","iopub.status.idle":"2024-12-03T15:34:59.339111Z","shell.execute_reply.started":"2024-12-03T15:34:55.720752Z","shell.execute_reply":"2024-12-03T15:34:59.338474Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2395e023b08c4469b701cfcefb679cfa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"136aa47abcc14857ba935d6bf4d849cc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0835e44a60fd4be5a1581bc58bd0b7e8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3575b01277024975ab3553dea10378bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a14b7c9017e43aca46c11cf1e8f2436"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Preprocess data\ndef preprocess_data(batch):\n    inputs = tokenizer(batch[\"claim\"], padding=\"max_length\", truncation=True, max_length=128)\n    inputs[\"labels\"] = [label2id[label] for label in batch[\"label\"]]\n    return inputs","metadata":{"id":"F14Hs48CMd3g","trusted":true,"execution":{"iopub.status.busy":"2024-12-03T15:34:59.340224Z","iopub.execute_input":"2024-12-03T15:34:59.340570Z","iopub.status.idle":"2024-12-03T15:34:59.345885Z","shell.execute_reply.started":"2024-12-03T15:34:59.340530Z","shell.execute_reply":"2024-12-03T15:34:59.344800Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# train_data = fever[\"train\"].map(preprocess_data, batched=True)\n# val_data = fever[\"labelled_dev\"].map(preprocess_data, batched=True)\n\n# train_data.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n# val_data.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])","metadata":{"id":"qa91HXnPAAFm","trusted":true,"execution":{"iopub.status.busy":"2024-12-03T15:34:59.346955Z","iopub.execute_input":"2024-12-03T15:34:59.347209Z","iopub.status.idle":"2024-12-03T15:34:59.360513Z","shell.execute_reply.started":"2024-12-03T15:34:59.347180Z","shell.execute_reply":"2024-12-03T15:34:59.359691Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"from datasets import Dataset\n\n# Function to sample equal examples for each class\ndef sample_equal_classes(dataset, label_column, num_samples_per_class):\n    sampled_data = []\n    for label in label2id.values():  # Iterate over label IDs\n        class_samples = dataset.filter(lambda x: label2id[x[label_column]] == label)\n        sampled_data.append(class_samples.select(range(min(num_samples_per_class, len(class_samples)))))\n    # Combine all class samples\n    return Dataset.from_dict({key: sum([d[key] for d in sampled_data], []) for key in dataset.column_names})\n\n# Sample 20,000 training examples and 5,000 validation examples\ntrain_data = sample_equal_classes(fever[\"train\"], \"label\", num_samples_per_class=100000 // len(label2id))\nval_data = sample_equal_classes(fever[\"labelled_dev\"], \"label\", num_samples_per_class=10000 // len(label2id))\n\n# Preprocess the data\ntrain_data = train_data.map(preprocess_data, batched=True)\nval_data = val_data.map(preprocess_data, batched=True)\n\n# Convert to PyTorch format\ntrain_data.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\nval_data.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n\n# Create DataLoaders\ntrain_dataloader = DataLoader(train_data, batch_size=32, shuffle=True)\nval_dataloader = DataLoader(val_data, batch_size=32)\n\nprint(f\"Training examples: {len(train_data)}, Validation examples: {len(val_data)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T15:34:59.361709Z","iopub.execute_input":"2024-12-03T15:34:59.362512Z","iopub.status.idle":"2024-12-03T15:35:39.034378Z","shell.execute_reply.started":"2024-12-03T15:34:59.362484Z","shell.execute_reply":"2024-12-03T15:35:39.033553Z"},"colab":{"base_uri":"https://localhost:8080/","height":99,"referenced_widgets":["c4d1d4203a8f46b0b3298f68627a2c64","0e48ba5970f74f01806aa9a025fb668a","671142ff85fa4647a167703e5fa41ef1","d84690912d934528bebeae11581799c5","e988aed855ca40f797105affde1f8b79","eed7404224174802983a5b4631c8b000","0558f714183f465683cec2971933ab97","ebbc7a2145504296b442e39b0486af82","aef76d301bd44687bf4d21506f5e3d11","78aee314a45448b7b03bf7d8cf893344","bfa696e15a7c415cb2f04f161ffebc59","00aaf32501a749dc824721e8644ac575","390c97b831ee48a9926a31faec6112ab","4023dd8ab62346c78f29ccb4aa26f812","0a4e88070eea48ca81e147cd42e84ca6","de377f7b0b714056bd087607b171a631","41b6dc9c8db64687b5c6ff59b3770306","dc73d5139ab545bea16b4ad664323cc5","b86ee503342f431da7019c357e1dfc46","5db907cf35e64b51b07f906e31ef5e69","fc8bcb34a11941639673c328f4c5e086","0c56e115172c4b1a926c0fa806db13ff"]},"id":"_gIGpYFtL5TD","outputId":"717e3b24-491f-4092-bfa4-27ebe5fe288e"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/311431 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e47691ab9704461d8604236774e772d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/311431 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2cf64f38be440c5a0e8cd501c3d025d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/311431 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9702a92ec8fb4ac5b7ff3909540c4e06"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/37566 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"401a9b96fdf24c2aa121fb217334f5cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/37566 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1da4df19d5c24e03b0c8777d4426ba7b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/37566 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12cb23a4abbe49a98d5595c8efaf7624"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/99999 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b84d4900c8474596801b2b1b74961b51"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/9999 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"913d41fedaa2484d8490b3f2ede917bb"}},"metadata":{}},{"name":"stdout","text":"Training examples: 99999, Validation examples: 9999\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# train_dataloader = DataLoader(train_data, batch_size=128, shuffle=True)\n# val_dataloader = DataLoader(val_data, batch_size=128)\n\n# Optimizer\noptimizer = AdamW(model.parameters(), lr=1e-5)\n\n# Training loop\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-2Q9cha3ACVm","outputId":"4c56d359-e0c7-482b-95d0-0f10c46c53df","trusted":true,"execution":{"iopub.status.busy":"2024-12-03T15:35:39.035712Z","iopub.execute_input":"2024-12-03T15:35:39.036367Z","iopub.status.idle":"2024-12-03T15:35:39.753706Z","shell.execute_reply.started":"2024-12-03T15:35:39.036326Z","shell.execute_reply":"2024-12-03T15:35:39.752828Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=3, bias=True)\n)"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"# from tqdm import tqdm\n\n# for epoch in range(10):  # Simplified to 1 epochs\n#     model.train()\n#     total_loss = 0\n\n#     # Wrap the DataLoader with TQDM for a progress bar\n#     train_progress = tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}\")\n\n#     for batch in train_progress:\n#         inputs = {key: val.to(device) for key, val in batch.items() if key != \"labels\"}\n#         labels = batch[\"labels\"].to(device)\n\n#         # Forward pass\n#         outputs = model(**inputs, labels=labels)\n#         loss = outputs.loss\n\n#         # Backward pass\n#         optimizer.zero_grad()\n#         loss.backward()\n#         optimizer.step()\n\n#         total_loss += loss.item()\n\n#         # Update TQDM with the current batch loss\n#         train_progress.set_postfix(loss=loss.item())\n\n#     # Print epoch-level loss\n#     print(f\"Epoch {epoch + 1}, Loss: {total_loss / len(train_dataloader):.4f}\")","metadata":{"id":"hFM5HNJJAgz1","trusted":true,"execution":{"iopub.status.busy":"2024-12-03T15:35:39.754956Z","iopub.execute_input":"2024-12-03T15:35:39.755563Z","iopub.status.idle":"2024-12-03T15:35:39.759999Z","shell.execute_reply.started":"2024-12-03T15:35:39.755522Z","shell.execute_reply":"2024-12-03T15:35:39.759129Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"from tqdm import tqdm\n\nfor epoch in range(10):  # Number of epochs\n    model.train()\n    total_loss = 0\n    correct_predictions = 0\n    total_predictions = 0\n\n    # Wrap the DataLoader with TQDM for a progress bar\n    train_progress = tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}\")\n\n    for batch in train_progress:\n        inputs = {key: val.to(device) for key, val in batch.items() if key != \"labels\"}\n        labels = batch[\"labels\"].to(device)\n\n        # Forward pass\n        outputs = model(**inputs, labels=labels)\n        loss = outputs.loss\n        logits = outputs.logits\n\n        # Backward pass\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n\n        # Calculate predictions and update accuracy metrics\n        predictions = torch.argmax(logits, dim=1)\n        correct_predictions += (predictions == labels).sum().item()\n        total_predictions += labels.size(0)\n\n        # Update TQDM with the current batch loss and accuracy\n        train_progress.set_postfix(loss=loss.item(), accuracy=correct_predictions / total_predictions)\n\n    # Calculate epoch-level accuracy\n    epoch_accuracy = correct_predictions / total_predictions\n\n    # Print epoch-level loss and accuracy\n    print(f\"Epoch {epoch + 1}, Loss: {total_loss / len(train_dataloader):.4f}, Accuracy: {epoch_accuracy:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T15:35:39.761022Z","iopub.execute_input":"2024-12-03T15:35:39.761365Z","iopub.status.idle":"2024-12-03T18:42:47.875537Z","shell.execute_reply.started":"2024-12-03T15:35:39.761338Z","shell.execute_reply":"2024-12-03T18:42:47.874679Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"Z3b3TIIwL5TF","outputId":"625d1188-852d-4f4b-a6e6-06b0ac99fbd7"},"outputs":[{"name":"stderr","text":"Epoch 1: 100%|██████████| 3125/3125 [18:41<00:00,  2.79it/s, accuracy=0.714, loss=0.564]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Loss: 0.6520, Accuracy: 0.7142\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2: 100%|██████████| 3125/3125 [18:42<00:00,  2.78it/s, accuracy=0.818, loss=0.583]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2, Loss: 0.4608, Accuracy: 0.8179\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3: 100%|██████████| 3125/3125 [18:43<00:00,  2.78it/s, accuracy=0.869, loss=0.384] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 3, Loss: 0.3469, Accuracy: 0.8695\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4: 100%|██████████| 3125/3125 [18:43<00:00,  2.78it/s, accuracy=0.903, loss=0.121] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 4, Loss: 0.2633, Accuracy: 0.9033\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5: 100%|██████████| 3125/3125 [18:43<00:00,  2.78it/s, accuracy=0.928, loss=0.29]  \n","output_type":"stream"},{"name":"stdout","text":"Epoch 5, Loss: 0.2011, Accuracy: 0.9279\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6: 100%|██████████| 3125/3125 [18:43<00:00,  2.78it/s, accuracy=0.945, loss=0.402] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 6, Loss: 0.1577, Accuracy: 0.9445\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7: 100%|██████████| 3125/3125 [18:43<00:00,  2.78it/s, accuracy=0.956, loss=0.109]  \n","output_type":"stream"},{"name":"stdout","text":"Epoch 7, Loss: 0.1250, Accuracy: 0.9565\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8: 100%|██████████| 3125/3125 [18:41<00:00,  2.79it/s, accuracy=0.964, loss=0.101]  \n","output_type":"stream"},{"name":"stdout","text":"Epoch 8, Loss: 0.1027, Accuracy: 0.9638\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9: 100%|██████████| 3125/3125 [18:41<00:00,  2.79it/s, accuracy=0.97, loss=0.0452]  \n","output_type":"stream"},{"name":"stdout","text":"Epoch 9, Loss: 0.0861, Accuracy: 0.9696\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10: 100%|██████████| 3125/3125 [18:42<00:00,  2.78it/s, accuracy=0.975, loss=0.055]   ","output_type":"stream"},{"name":"stdout","text":"Epoch 10, Loss: 0.0733, Accuracy: 0.9747\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, classification_report\n\n\nmodel.eval()\nall_preds = []\nall_labels = []\n\nwith torch.no_grad():\n    for batch in val_dataloader:\n        inputs = {key: val.to(device) for key, val in batch.items() if key != \"labels\"}\n        labels = batch[\"labels\"].to(device)\n\n        outputs = model(**inputs)\n        logits = outputs.logits\n\n        # Get predictions (the index of the highest logit)\n        preds = torch.argmax(logits, dim=1)\n\n        all_preds.extend(preds.cpu().numpy())\n        all_labels.extend(labels.cpu().numpy())\n\naccuracy = accuracy_score(all_labels, all_preds)\nprint(f\"Validation Accuracy: {accuracy:.4f}\")\nprint(\"Classification Report:\")\nprint(classification_report(all_labels, all_preds, target_names=[\"SUPPORTS\", \"REFUTES\", \"NOT ENOUGH INFO\"]))","metadata":{"id":"SFBpOtTsNJ07","trusted":true,"colab":{"base_uri":"https://localhost:8080/","height":216},"outputId":"cf014ac8-e707-4cf6-8dde-58a96a2f9f59","execution":{"iopub.status.busy":"2024-12-03T18:42:47.876687Z","iopub.execute_input":"2024-12-03T18:42:47.876957Z","iopub.status.idle":"2024-12-03T18:43:21.263264Z","shell.execute_reply.started":"2024-12-03T18:42:47.876932Z","shell.execute_reply":"2024-12-03T18:43:21.262303Z"}},"outputs":[{"name":"stdout","text":"Validation Accuracy: 0.6477\nClassification Report:\n                 precision    recall  f1-score   support\n\n       SUPPORTS       0.63      0.70      0.66      3333\n        REFUTES       0.75      0.63      0.68      3333\nNOT ENOUGH INFO       0.59      0.61      0.60      3333\n\n       accuracy                           0.65      9999\n      macro avg       0.65      0.65      0.65      9999\n   weighted avg       0.65      0.65      0.65      9999\n\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Function to predict the class of a particular claim\ndef predict_claim_class(claim):\n    # Preprocess the claim (same way as during training)\n    inputs = tokenizer(claim, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\").to(device)\n\n    # Make predictions\n    with torch.no_grad():\n        outputs = model(**inputs)\n        logits = outputs.logits\n\n    # Get the predicted class (index of max logit)\n    predicted_class_id = torch.argmax(logits, dim=1).item()\n\n    # Convert class ID to label\n    predicted_label = id2label[predicted_class_id]\n\n    return predicted_label\n","metadata":{"trusted":true,"id":"-MyHslatL5TF","execution":{"iopub.status.busy":"2024-12-03T18:43:21.264680Z","iopub.execute_input":"2024-12-03T18:43:21.265568Z","iopub.status.idle":"2024-12-03T18:43:21.270806Z","shell.execute_reply.started":"2024-12-03T18:43:21.265508Z","shell.execute_reply":"2024-12-03T18:43:21.269904Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# Example usage:\nclaim = \"The Atlantic Ocean is the largest ocean on Earth.\"\npredicted_label = predict_claim_class(claim)\nprint(f\"The claim '{claim}' belongs to the class: {predicted_label}\")","metadata":{"trusted":true,"id":"SNYzz-XiL5TF","execution":{"iopub.status.busy":"2024-12-03T18:43:21.271881Z","iopub.execute_input":"2024-12-03T18:43:21.272212Z","iopub.status.idle":"2024-12-03T18:43:21.306895Z","shell.execute_reply.started":"2024-12-03T18:43:21.272171Z","shell.execute_reply":"2024-12-03T18:43:21.306162Z"}},"outputs":[{"name":"stdout","text":"The claim 'The Atlantic Ocean is the largest ocean on Earth.' belongs to the class: SUPPORTS\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"","metadata":{"trusted":true,"id":"3kntvb2CL5TG"},"outputs":[],"execution_count":null}]}